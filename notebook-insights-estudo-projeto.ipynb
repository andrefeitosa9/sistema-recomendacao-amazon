{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideias para o sistema de recomendação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## estudar esses imports\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boa prática diz que você deve criar um range de tempo para analisar produtos, compras e interações que estavam disponíveis naquele período.\n",
    "Isso faz sentido pois, se um dado produto foi ofertado depois e fez sucesso, ele pode não performar também ou não ter tantas interações quanto outro com mais tempo\n",
    "o penalizando e fazendo com que o algoritmo não entenda a importância dessa combinação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dar peso diferentes à interações de compra (Adicionar ao carrinho, prosseguir para pagamento, realizar pagamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistemas de recomendação sentem uma dificuldade em lidar com pouca informação, interação (user cold-start). Por isso, normalmente são separados para treinamento de modelo usuários com no mínimo um limiar de transações (Foi usado 5 no artigo base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### Como calcular essa quantidade de usuários com o limiar de transações \n",
    "\n",
    "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A avaliação do modelo pode ser feita por dois meios principais, pensando em cross-validation:\n",
    "- Holdout - Deixando uma parte dos dados de interações compras de fora do modelo de treino para serem utilizados no modelo de teste. \n",
    "- Train test Split baseado em uma data - Definir uma data X para treinar em X-infinito e testar em X + infinito.\n",
    "\n",
    "Acredito que para usar train teste temos que ter muitos dados de usuários, interações realmente muito recorrentes, como plataformas de streaming (música ou filmes/séries)\n",
    "Em compras o melhor seria holdout, por não ter certeza que teremos tantas interações futuras assim\n",
    "\n",
    "Nesse ponto entra também o problema \"naive\" que é crer que serão analisados somente usuários que estão presentes durante todo o recorte feito para treinamento e teste do modelo, o que sabemos que é praticamente impossível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medição de Acurácia nesses modelos\n",
    "\n",
    "Em sistemas de recomendação, existem algumas métrias que são usadas de forma mais recorrente nas avaliação. Iremos utilizar métricas do tipo Top-N Accuracy Metrics, que avaliam a acurácia das recomendações principais à um usuário, comparando com os itens que ele realmente escolheu nos dados de teste.\n",
    "Funciona da seguinte forma:\n",
    "\n",
    "* Para cada usuário\n",
    "    * Para cada item que esse usuário interagiu nos dados de teste\n",
    "        * Crie uma amostra de outros 100 itens que esse usuário nunca interagiu   \n",
    "        Ps. Aqui, novamente de forma \"Naive\" nós vamos assumir que os itens que o usuário nunca interagiu não são relevante para o mesmo, o que não pode ser verdade, pois ele pode não ter interagido com esses itens simplesmente por não saber da existência dos mesmos. Mas iremos manter assim\n",
    "        * Peça para o modelo de recomendação produzir uma lista ranqueada dos 101 itens (o item que o usuário interagiu e os outros 100 \"não relevantes\")\n",
    "        * Calcule e guarde a métrica de Top-N accuracy para esse usuário e o item que ele realmente interagiu na lista ranqueada produzida\n",
    "* Junte todas as métricas do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas a serem utilizadas nesse tipo de avaliação (Top-N Accuracy Metrics):\n",
    "\n",
    "- Recall@N - Iremos utilizar nesse modelo\n",
    "- NDCG@N\n",
    "- MAP@N\n",
    "\n",
    "Link para mais informações sobre as outras duas [aqui](http://fastml.com/evaluating-recommender-systems/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Indexando pelo ID para facilitar a separação dos grupos\n",
    "\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('personId')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('personId')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('personId')\n",
    "\n",
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id]['contentId']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parei aqui\n",
    "\n",
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
